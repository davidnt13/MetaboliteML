{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWdzoKSTa03R"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhYEleS_a6Bh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71zjBKzzk--l"
   },
   "outputs": [],
   "source": [
    "def importStatements():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import Descriptors\n",
    "    from rdkit.Chem import AllChem\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import r2_score, mean_squared_error\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.model_selection import KFold, cross_val_score\n",
    "    from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from xgboost import XGBRegressor\n",
    "    from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTypes = {}\n",
    "modelTypes['RF'] = RandomForestRegressor()\n",
    "modelTypes['XGBR'] = XGBRegressor()\n",
    "modelTypes['SVR'] = SVR() \n",
    "modelTypes['SVRLinear'] = SVR(kernel = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDpAoW2Aa6X_"
   },
   "outputs": [],
   "source": [
    "def CalcRDKitDescriptors(fileName):\n",
    "    df = pd.read_csv(fileName)\n",
    "    smiles_strings = df['SMILES'].tolist()\n",
    "    mySmiles = [Chem.MolFromSmiles(mol) for mol in smiles_strings]\n",
    "    myDescriptors = [Descriptors.CalcMolDescriptors(mol) for mol in mySmiles]\n",
    "    return pd.DataFrame(myDescriptors, index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morganHelper(smiles, radius=2, n_bits=1024):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    return list(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcMorganFingerprints(fileName):\n",
    "    df = pd.read_csv(fileName)\n",
    "    df['MorganFingerprint'] = df['SMILES'].apply(morganHelper)\n",
    "    df = df.dropna(subset=['MorganFingerprint'])\n",
    "    return pd.DataFrame(df['MorganFingerprint'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcBothDescriptors(fileName):\n",
    "    dfMorgan = CalcMorganFingerprints(fileName)\n",
    "    dfDescr = CalcRDKitDescriptors(fileName)\n",
    "    bothDescr = pd.concat([dfDescr, dfMorgan], axis=1)\n",
    "    bothDescr.columns = bothDescr.columns.astype(str)\n",
    "    return bothDescr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ir7Ho2uDb1DD"
   },
   "outputs": [],
   "source": [
    "def makeTrainAndTest(fileNameTrain, fileNameTest, target, desc):\n",
    "    dfTrain = pd.read_csv(fileNameTrain)\n",
    "    dfTest = pd.read_csv(fileNameTest)\n",
    "\n",
    "    if desc == \"RDKit\":\n",
    "        descTrain = CalcRDKitDescriptors(fileNameTrain)\n",
    "        descTest = CalcRDKitDescriptors(fileNameTest)\n",
    "    elif desc == \"Morgan\":\n",
    "        descTrain = CalcMorganFingerprints(fileNameTrain)\n",
    "        descTest = CalcMorganFingerprints(fileNameTest)\n",
    "    elif desc == \"Both\":\n",
    "        descTrain = calcBothDescriptors(fileNameTrain)\n",
    "        descTest = calcBothDescriptors(fileNameTest)\n",
    "    \n",
    "    train_X = descTrain.dropna(axis = 1)\n",
    "    train_y = dfTrain[target]\n",
    "    test_X = descTest.dropna(axis = 1)\n",
    "    test_y = dfTest[target]\n",
    "    \n",
    "    common_columns = train_X.columns.intersection(test_X.columns)\n",
    "    train_X = train_X[common_columns]\n",
    "    test_X = test_X[common_columns]\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCVResults(modelType, train_y, myPreds, title):\n",
    "    \n",
    "    nptrain_y = train_y.to_numpy() if isinstance(train_y, pd.Series) else train_y\n",
    "    npy_pred = myPreds['Prediction']\n",
    "    \n",
    "    minVal = min(nptrain_y.min(), npy_pred.min())\n",
    "    maxVal = max(nptrain_y.max(), npy_pred.max())\n",
    "    \n",
    "    a, b = np.polyfit(nptrain_y, npy_pred, 1)\n",
    "    xvals = np.linspace(minVal - 1, maxVal + 1, 100)\n",
    "    yvals = xvals\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(xvals, yvals, '--')\n",
    "    ax.scatter(nptrain_y, npy_pred)\n",
    "    ax.plot(nptrain_y, a * nptrain_y + b)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'{title}: CV {modelType} Model Results')\n",
    "    plt.savefig(f'{title}: CV{modelType}_modelResults.png')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loopedKfoldCrossVal(modelType, cycleNum, train_X, train_y, title, distributor = None):\n",
    "    num_cv = cycleNum\n",
    "    predictions_filename = f'{title}: CV{modelType}_predictions.csv'\n",
    "\n",
    "    predStats = {'r2_sum': 0, 'rmsd_sum': 0, 'bias_sum': 0, 'sdep_sum': 0}\n",
    "    predictionStats = pd.DataFrame(data=np.zeros((num_cv, 6)), columns=['Fold', 'Number of Molecules', 'r2', 'rmsd', 'bias', 'sdep'])\n",
    "\n",
    "    myPreds = pd.DataFrame(index=train_y.index, columns=['Prediction', 'Fold'])\n",
    "    myPreds['Prediction'] = np.nan\n",
    "    myPreds['Fold'] = np.nan\n",
    "\n",
    "    if distributor == None:\n",
    "        train_test_split = KFold(n_splits = num_cv, shuffle=True, random_state=1)\n",
    "    else:\n",
    "        train_test_split = StratifiedKFold(n_splits = num_cv, shuffle = True, random_state = 1)\n",
    "\n",
    "    for n, (train_idx, test_idx) in enumerate(train_test_split.split(train_X, distributor)):\n",
    "        x_train = train_X.iloc[train_idx]\n",
    "        x_test = train_X.iloc[test_idx]\n",
    "        y_train = train_y.iloc[train_idx]\n",
    "        y_test = train_y.iloc[test_idx]\n",
    "\n",
    "        model = modelTypes[modelType]\n",
    "\n",
    "        # Train model\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        # Metrics calculations\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmsd = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        bias = np.mean(y_pred - y_test)\n",
    "        sdep = np.std(y_pred - y_test)\n",
    "\n",
    "        # Update stats\n",
    "        predStats['r2_sum'] += r2\n",
    "        predStats['rmsd_sum'] += rmsd\n",
    "        predStats['bias_sum'] += bias\n",
    "        predStats['sdep_sum'] += sdep\n",
    "\n",
    "        # Update predictions\n",
    "        myPreds.loc[test_idx, 'Prediction'] = y_pred\n",
    "        myPreds.loc[test_idx, 'Fold'] = n + 1\n",
    "\n",
    "        # Ensure correct number of values are assigned\n",
    "        predictionStats.iloc[n] = [n + 1, len(test_idx), r2, rmsd, bias, sdep]\n",
    "\n",
    "    # Calculate averages\n",
    "    r2_av = predStats['r2_sum'] / num_cv\n",
    "    rmsd_av = predStats['rmsd_sum'] / num_cv\n",
    "    bias_av = predStats['bias_sum'] / num_cv\n",
    "    sdep_av = predStats['sdep_sum'] / num_cv\n",
    "\n",
    "    # Create a DataFrame row for averages\n",
    "    avg_row = pd.DataFrame([['Average', len(train_y), r2_av, rmsd_av, bias_av, sdep_av]], columns=predictionStats.columns)\n",
    "\n",
    "    # Append average row to the DataFrame\n",
    "    predictionStats = pd.concat([predictionStats, avg_row], ignore_index=True)\n",
    "\n",
    "    myPreds.to_csv(predictions_filename, index=True)\n",
    "    predictionStats.to_csv(f'{title}: CV{modelType}_stats.csv', index=False)\n",
    "\n",
    "    plotCVResults(modelType, train_y, myPreds, title)\n",
    "\n",
    "    return myPreds, predictionStats, avg_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loopedKfoldCrossValMix(modelType, cycleNum, train_X, train_y, title, distributor = None):\n",
    "    num_cv = cycleNum\n",
    "    predictions_filename = f'{title}: CV{modelType}_predictions.csv'\n",
    "\n",
    "    predStats = {'r2_sum': 0, 'rmsd_sum': 0, 'bias_sum': 0, 'sdep_sum': 0}\n",
    "    predictionStats = pd.DataFrame(data=np.zeros((num_cv, 6)), columns=['Fold', 'Number of Molecules', 'r2', 'rmsd', 'bias', 'sdep'])\n",
    "\n",
    "    myPreds = pd.DataFrame(index=train_y.index, columns=['Prediction', 'Fold'])\n",
    "    myPreds['Prediction'] = np.nan\n",
    "    myPreds['Fold'] = np.nan\n",
    "\n",
    "    if distributor == None:\n",
    "        train_test_split = KFold(n_splits = num_cv, shuffle=True, random_state=1)\n",
    "    else:\n",
    "        train_test_split = StratifiedKFold(n_splits = num_cv, shuffle = True, random_state = 1)\n",
    "\n",
    "    for n, (train_idx, test_idx) in enumerate(train_test_split.split(train_X, distributor)):\n",
    "        x_train = train_X.iloc[train_idx]\n",
    "        x_test = train_X.iloc[test_idx]\n",
    "        y_train = train_y.iloc[train_idx]\n",
    "        y_test = train_y.iloc[test_idx]\n",
    "\n",
    "        model = modelTypes[modelType]\n",
    "\n",
    "        # Train model\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        # Metrics calculations\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmsd = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        bias = np.mean(y_pred - y_test)\n",
    "        sdep = np.std(y_pred - y_test)\n",
    "\n",
    "        # Update stats\n",
    "        predStats['r2_sum'] += r2\n",
    "        predStats['rmsd_sum'] += rmsd\n",
    "        predStats['bias_sum'] += bias\n",
    "        predStats['sdep_sum'] += sdep\n",
    "\n",
    "        # Update predictions\n",
    "        myPreds.loc[test_idx, 'Prediction'] = y_pred\n",
    "        myPreds.loc[test_idx, 'Fold'] = n + 1\n",
    "\n",
    "        # Ensure correct number of values are assigned\n",
    "        predictionStats.iloc[n] = [n + 1, len(test_idx), r2, rmsd, bias, sdep]\n",
    "\n",
    "    # Calculate averages\n",
    "    r2_av = predStats['r2_sum'] / num_cv\n",
    "    rmsd_av = predStats['rmsd_sum'] / num_cv\n",
    "    bias_av = predStats['bias_sum'] / num_cv\n",
    "    sdep_av = predStats['sdep_sum'] / num_cv\n",
    "\n",
    "    # Create a DataFrame row for averages\n",
    "    avg_row = pd.DataFrame([['Average', len(train_y), r2_av, rmsd_av, bias_av, sdep_av]], columns=predictionStats.columns)\n",
    "\n",
    "    # Append average row to the DataFrame\n",
    "    predictionStats = pd.concat([predictionStats, avg_row], ignore_index=True)\n",
    "\n",
    "    # myPreds.to_csv(predictions_filename, index=True)\n",
    "    # predictionStats.to_csv(f'{title}: CV{modelType}_stats.csv', index=False)\n",
    "\n",
    "    # plotCVResults(modelType, train_y, myPreds, title)\n",
    "\n",
    "    return myPreds, predictionStats, avg_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixedCV(fileName, descr, model):\n",
    "\n",
    "    mixDf = pd.read_csv(fileName)\n",
    "\n",
    "    if descr == \"RDKit\":\n",
    "        df2Mix = CalcRDKitDescriptors(fileName)\n",
    "    elif descr == \"Morgan\":\n",
    "        df2Mix = CalcMorganFingerprints(fileName)\n",
    "    elif descr == \"Both\":\n",
    "        df2Mix = calcBothDescriptors(fileName)\n",
    "\n",
    "    allMetabolites = mixDf[\"natural_product\"].tolist()\n",
    "    df2Mix[\"natural_product\"] = allMetabolites\n",
    "    train_X = df2Mix.dropna(axis = 1)\n",
    "    train_y = mixDf.pIC50\n",
    "    metabolites = mixDf.natural_product\n",
    "    train_X = train_X.drop(\"natural_product\", axis = 1)\n",
    "\n",
    "    for index in range(1, 4):\n",
    "        loopedKfoldCrossVal(model, 10, train_X, train_y, f\"Mixture + {model} + {descr} + {index}\", metabolites)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixedCVSaveAvg(fileName, descr, model):\n",
    "    \n",
    "    mixDf = pd.read_csv(fileName)\n",
    "\n",
    "    if descr == \"RDKit\":\n",
    "        df2Mix = CalcRDKitDescriptors(fileName)\n",
    "    elif descr == \"Morgan\":\n",
    "        df2Mix = CalcMorganFingerprints(fileName)\n",
    "    elif descr == \"Both\":\n",
    "        df2Mix = calcBothDescriptors(fileName)\n",
    "\n",
    "    allMetabolites = mixDf[\"natural_product\"].tolist()\n",
    "    df2Mix[\"natural_product\"] = allMetabolites\n",
    "    train_X = df2Mix.dropna(axis = 1)\n",
    "    train_y = mixDf.pIC50\n",
    "    metabolites = mixDf.natural_product\n",
    "    train_X = train_X.drop(\"natural_product\", axis = 1)\n",
    "\n",
    "    avgResults = pd.DataFrame(data= [], columns=['Fold', 'Number of Molecules', 'r2', 'rmsd', 'bias', 'sdep', 'Model', 'Descriptor', 'Index'])\n",
    "\n",
    "    for index in range(1, 4):\n",
    "        _,_, avgVals = loopedKfoldCrossVal(model, 10, train_X, train_y, f\"Mixture + {model} + {descr} + {index}\", metabolites)\n",
    "        avgVals['Model'] = model\n",
    "        avgVals['Descriptor'] = descr\n",
    "        avgVals['Index'] = index\n",
    "        avgResults = pd.concat([avgResults, avgVals])\n",
    "        \n",
    "    return avgResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSplitsBarChart(predictionStats, title):\n",
    "\n",
    "    columns_to_plot = ['r2', 'rmsd', 'bias', 'sdep']\n",
    "    df = predictionStats.iloc[:-1]  # Exclude the last row\n",
    "\n",
    "    num_rows = 5\n",
    "    num_cols = int(df.shape[0] / num_rows) + (df.shape[0] % num_rows > 0)\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, num_rows * 4), constrained_layout=True)\n",
    "    axes = axes.flatten()  # Reshape to 1D array even for single row\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        row_to_plot = row[columns_to_plot]\n",
    "        axes[idx].bar(columns_to_plot, row_to_plot)\n",
    "        axes[idx].set_title(f'Fold {idx + 1}')\n",
    "        \n",
    "    plt.savefig(f'{title}: StatisticsPerFold.png')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAvgBarChart(predictionStats, title):\n",
    "    df = predictionStats.iloc[:-1]\n",
    "    cols = ['r2', 'rmsd', 'bias', 'sdep']\n",
    "    \n",
    "    means, stds = df[cols].mean(), df[cols].std()\n",
    "    \n",
    "    plt.bar(cols, means, yerr=stds, capsize=7)\n",
    "    plt.xlabel('Statistic')\n",
    "    plt.ylabel('Value (Mean ± Standard Deviation)')\n",
    "    plt.title(f'{title}: Average Prediction Statistics')\n",
    "    plt.savefig(f'{title}: AverageStatsCV.png')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping in case stuff is out of whack\n",
    "def createSplitsBarChart2 (predictionStats):\n",
    "\n",
    "    columns_to_plot = ['r2', 'rmsd', 'bias', 'sdep']\n",
    "    df = predictionStats.drop(predictionStats.shape[0] - 1)\n",
    "    num_rows = df.shape[0]\n",
    "    fig, axes = plt.subplots(int(num_rows / 5), 5, figsize=(10, num_rows * 4), constrained_layout=True)\n",
    "\n",
    "    # If there's only one row, axes won't be an array, so we need to handle that case\n",
    "    if num_rows == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Iterate through each row and plot\n",
    "    for idx in range(num_rows):\n",
    "        ax = axes[idx]\n",
    "        row_to_plot = df.loc[idx, columns_to_plot]\n",
    "        ax.bar(columns_to_plot, row_to_plot, color='skyblue', edgecolor='black')\n",
    "        ax.set_title(f'Fold {idx + 1}')\n",
    "        ax.set_ylabel('Values')\n",
    "        ax.set_xlabel('Categories')\n",
    "\n",
    "    # Display the plot\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gk-Gqisf1tu_",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Kept in case the above function did not work\n",
    "\n",
    "def loopedKfoldCrossVal2(modelType, cycleNum, train_X, train_y):\n",
    "    modelTypes = {'RF': RandomForestRegressor()}\n",
    "\n",
    "    num_cv = cycleNum\n",
    "    predictions_filename = f'CV{modelType}_predictions.csv'\n",
    "\n",
    "    predStats = {'r2_sum': 0, 'rmsd_sum': 0, 'bias_sum': 0, 'sdep_sum': 0}\n",
    "    predictionStats = pd.DataFrame(data=np.zeros((num_cv, 6)), columns=['Fold', 'Number of Molecules', 'r2', 'rmsd', 'bias', 'sdep'])\n",
    "\n",
    "    myPreds = pd.DataFrame(index=train_y.index, columns=['Prediction', 'Fold'])\n",
    "    myPreds['Prediction'] = np.nan\n",
    "    myPreds['Fold'] = np.nan\n",
    "\n",
    "    train_test_split = KFold(n_splits=num_cv, shuffle=True, random_state=1)\n",
    "\n",
    "    for n, (train_idx, test_idx) in enumerate(train_test_split.split(train_X)):\n",
    "        x_train = train_X.iloc[train_idx]\n",
    "        x_test = train_X.iloc[test_idx]\n",
    "        y_train = train_y.iloc[train_idx]\n",
    "        y_test = train_y.iloc[test_idx]\n",
    "\n",
    "        model = modelTypes[modelType]\n",
    "\n",
    "        # Train model\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        # Metrics calculations\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmsd = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        bias = np.mean(y_pred - y_test)\n",
    "        sdep = np.std(y_pred - y_test)\n",
    "\n",
    "        # Update stats\n",
    "        predStats['r2_sum'] += r2\n",
    "        predStats['rmsd_sum'] += rmsd\n",
    "        predStats['bias_sum'] += bias\n",
    "        predStats['sdep_sum'] += sdep\n",
    "\n",
    "        # Update predictions\n",
    "        myPreds.loc[test_idx, 'Prediction'] = y_pred\n",
    "        myPreds.loc[test_idx, 'Fold'] = n + 1\n",
    "\n",
    "        # Ensure correct number of values are assigned\n",
    "        predictionStats.iloc[n] = [n + 1, len(test_idx), r2, rmsd, bias, sdep]\n",
    "\n",
    "    # Calculate averages\n",
    "    r2_av = predStats['r2_sum'] / num_cv\n",
    "    rmsd_av = predStats['rmsd_sum'] / num_cv\n",
    "    bias_av = predStats['bias_sum'] / num_cv\n",
    "    sdep_av = predStats['sdep_sum'] / num_cv\n",
    "\n",
    "    # Create a DataFrame row for averages\n",
    "    avg_row = pd.DataFrame([['Average', len(train_y), r2_av, rmsd_av, bias_av, sdep_av]], columns=predictionStats.columns)\n",
    "\n",
    "    # Append average row to the DataFrame\n",
    "    predictionStats = pd.concat([predictionStats, avg_row], ignore_index=True)\n",
    "\n",
    "    myPreds.to_csv(predictions_filename, index=True)\n",
    "    predictionStats.to_csv(f'CV{modelType}_stats.csv', index=False)\n",
    "\n",
    "    return myPreds, predictionStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHXBHsnd4omT",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Also kept in case the above function did not work\n",
    "\n",
    "def loopedStratKfoldCrossVal(modelType, cycleNum, train_X, train_y, distributor):\n",
    "\n",
    "  num_cv = cycleNum\n",
    "\n",
    "  predictions_filename = f'CV{modelType}_predictions.csv'\n",
    "\n",
    "  predStats = {'r2_sum': 0, 'rmsd_sum': 0, 'bias_sum': 0, 'sdep_sum': 0}\n",
    "  predictionStats = pd.DataFrame(data = np.zeros((num_cv, 6)), columns = ['Fold', 'Number of Molecules', 'r2', 'rmsd', 'bias', 'sdep'])\n",
    "\n",
    "  myPreds = pd.DataFrame(data = np.zeros((len(train_y), 2)), index = train_y.index, columns = ['Prediction', 'Fold'])\n",
    "  myPreds['Prediction'] = np.nan\n",
    "  myPreds['Fold'] = np.nan\n",
    "\n",
    "  train_test_split = StratifiedKFold(n_splits = num_cv, shuffle = True, random_state = 1)\n",
    "\n",
    "  for n, [train_idx, test_idx] in enumerate(train_test_split.split(train_X, distributor)):\n",
    "\n",
    "    train_idx = train_y.index[train_idx]\n",
    "    test_idx = train_y.index[test_idx]\n",
    "\n",
    "    x_train = train_X.loc[train_idx]\n",
    "    x_test = train_X.loc[test_idx]\n",
    "    y_train = train_y.loc[train_idx]\n",
    "    y_test = train_y.loc[test_idx]\n",
    "\n",
    "    model = modelTypes[modelType]\n",
    "\n",
    "    # Train RF model:\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Coefficient of determination\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    # Root mean squared error\n",
    "    rmsd = mean_squared_error(y_test, y_pred)**0.5\n",
    "    # Bias\n",
    "    bias = np.mean(y_pred - y_test)\n",
    "    # Standard deviation of the error of prediction\n",
    "    sdep = np.mean(((y_pred - y_test) - np.mean(y_pred - y_test))**2)**0.5\n",
    "\n",
    "    # Save running sum of results:\n",
    "    predStats['r2_sum'] += r2\n",
    "    predStats['rmsd_sum'] += rmsd\n",
    "    predStats['bias_sum'] += bias\n",
    "    predStats['sdep_sum'] += sdep\n",
    "\n",
    "    # Save individual predictions:\n",
    "\n",
    "    myPreds.loc[test_idx, 'Prediction'] = y_pred\n",
    "    myPreds.loc[test_idx, 'Fold'] = n + 1\n",
    "\n",
    "    predictionStats.loc[n, :] = [n + 1, len(test_idx), r2, rmsd, bias, sdep]\n",
    "\n",
    "  # Average results over resamples:\n",
    "  r2_av = predStats['r2_sum']/num_cv\n",
    "  rmsd_av = predStats['rmsd_sum']/num_cv\n",
    "  bias_av = predStats['bias_sum']/num_cv\n",
    "  sdep_av = predStats['sdep_sum']/num_cv\n",
    "  avg_row = pd.DataFrame([['Average', len(train_y), r2_av, rmsd_av, bias_av, sdep_av]], columns=predictionStats.columns)\n",
    "  predictionStats = pd.concat([predictionStats, avg_row], ignore_index=True)\n",
    "\n",
    "  myPreds.to_csv(predictions_filename, index=True)\n",
    "  predictionStats.to_csv(f'CV{modelType}_stats.csv', index=False)\n",
    "\n",
    "  return myPreds, predictionStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelStats(test_y, y_pred):\n",
    "    # Coefficient of determination\n",
    "    r2 = r2_score(test_y, y_pred)\n",
    "    # Root mean squared error\n",
    "    rmsd = mean_squared_error(test_y, y_pred)**0.5\n",
    "    # Bias\n",
    "    bias = np.mean(y_pred - test_y)\n",
    "    # Standard deviation of the error of prediction\n",
    "    sdep = np.mean(((y_pred - test_y) - np.mean(y_pred - test_y))**2)**0.5\n",
    "    return r2, rmsd, bias, sdep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_39C1Hu5EJk0"
   },
   "outputs": [],
   "source": [
    "def plotter(modelType, test_y, y_pred, title):\n",
    "    \n",
    "    r2, rmsd, bias, sdep = modelStats(test_y, y_pred)\n",
    "    statisticValues = f\"r2: {round(r2, 3)}\\nrmsd: {round(rmsd, 3)}\\nbias: {round(bias, 3)}\\nsdep: {round(sdep, 3)}\"\n",
    "    \n",
    "    nptest_y = test_y.to_numpy() if isinstance(test_y, pd.Series) else test_y\n",
    "    npy_pred = y_pred\n",
    "    \n",
    "    minVal = min(nptest_y.min(), npy_pred.min())\n",
    "    maxVal = max(nptest_y.max(), npy_pred.max())\n",
    "    \n",
    "    a, b = np.polyfit(test_y, y_pred, 1)\n",
    "    xvals = np.linspace(minVal - 1, maxVal + 1, 100)\n",
    "    yvals = xvals\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(xvals, yvals, '--')\n",
    "    ax.scatter(nptest_y, npy_pred)\n",
    "    ax.plot(nptest_y, a * nptest_y + b)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'{title}: {modelType} Model')\n",
    "    ax.text(0.01, 0.99, statisticValues, transform=ax.transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left')\n",
    "    plt.savefig(f'{title}: {modelType}_model.png')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listAvg2(df, index, modelVars, test_y, y_pred):\n",
    "    r2, rmsd, bias, sdep = modelStats(test_y, y_pred)\n",
    "    stats = [r2, rmsd, bias, sdep, index]\n",
    "    modelVars.extend(stats)\n",
    "    df_new = df\n",
    "    df_new.loc[len(df_new)] = modelVars\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listAvg(df, index, model_vars, test_y, y_pred):\n",
    "    \n",
    "    r2, rmsd, bias, sdep = modelStats(test_y, y_pred)\n",
    "    stats = [r2, rmsd, bias, sdep, index]\n",
    "    \n",
    "    combined_vars = model_vars + stats\n",
    "    \n",
    "    df_new = df.copy()\n",
    "    \n",
    "    df_new.loc[len(df_new)] = combined_vars\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping in case above function doesn't work\n",
    "def plotter2(modelType, test_y, y_pred):\n",
    "    \n",
    "    r2, rmsd, bias, sdep = modelStats(test_y, y_pred)\n",
    "    statisticValues = f\"r2: {round(r2, 3)}\\nrmsd: {round(rmsd, 3)}\\nbias: {round(bias, 3)}\\nsdep: {round(sdep, 3)}\"\n",
    "    \n",
    "    nptest_y = test_y.to_numpy() if isinstance(test_y, pd.Series) else test_y\n",
    "    npy_pred = y_pred\n",
    "    \n",
    "    minVal = min(nptest_y.min(), npy_pred.min())\n",
    "    maxVal = max(nptest_y.max(), npy_pred.max())\n",
    "    \n",
    "    a, b = np.polyfit(test_y, y_pred, 1)\n",
    "    xvals = np.linspace(minVal - 1, maxVal + 1, 100)\n",
    "    yvals = xvals\n",
    "    \n",
    "    plt.plot(xvals, yvals, '--')\n",
    "    plt.scatter(nptest_y, npy_pred)\n",
    "    plt.plot(test_y, a*test_y+b)\n",
    "    plt.xlabel('Measured')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.xlim(minVal - 1, maxVal + 1)\n",
    "    plt.ylim(minVal - 1, maxVal + 1)\n",
    "    plt.title(f'{modelType} Model')\n",
    "    plt.text(0.01, 0.99, statisticValues, transform=plt.gca().transAxes, fontsize=12, verticalalignment='top', horizontalalignment='left')\n",
    "    plt.savefig(f'{modelType}_model.png')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIyTNZdN8gsV"
   },
   "outputs": [],
   "source": [
    "def plotModel(modelType, train_X, train_y, test_X, test_y, title):\n",
    "    model = modelTypes[modelType]\n",
    "    model.fit(train_X, train_y)\n",
    "    y_pred = model.predict(test_X)\n",
    "    plotter(modelType, test_y, y_pred, title)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ro_dC0z-zbZ",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Ignore: Prior Attempt\n",
    "\n",
    "def metaboliteRFModelStuff(fileNameTrain, fileNameTest):\n",
    "    train_X, train_y, test_X, test_y = makeTrainAndTest(fileNameTrain, fileNameTest, 'pIC50')\n",
    "    myPreds, predictionStats = loopedKfoldCrossVal('RF', 10, train_X, train_y)\n",
    "    createSplitsBarChart(predictionStats)\n",
    "    createAvgBarChart(predictionStats)\n",
    "    plotModel('RF', train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel2(fileNameTrain, fileNameTest, desc, model, title, distributor = None):\n",
    "    train_X, train_y, test_X, test_y = makeTrainAndTest(fileNameTrain, fileNameTest, 'pIC50', desc)\n",
    "    myPreds, predictionStats = loopedKfoldCrossVal(model, 10, train_X, train_y, title, distributor)\n",
    "    createSplitsBarChart(predictionStats, title)\n",
    "    createAvgBarChart(predictionStats, title)\n",
    "    plotModel(model, train_X, train_y, test_X, test_y, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel(fileNameTrain, fileNameTest, desc, model, title, distributor = None):\n",
    "    train_X, train_y, test_X, test_y = makeTrainAndTest(fileNameTrain, fileNameTest, 'pIC50', desc)\n",
    "    df = pd.DataFrame(data = [], columns = ['Descriptors',\t'Model', 'Train','Test', 'R2', 'RMSD', 'Bias', 'SDEP', 'Index'])\n",
    "    modelVars = [desc, model, fileNameTrain, fileNameTest]\n",
    "    for i in range(1, 4):\n",
    "        myPreds, predictionStats = loopedKfoldCrossVal(model, 10, train_X, train_y, f\"{title} + {i}\", distributor)\n",
    "        createSplitsBarChart(predictionStats, f\"{title} + {i}\")\n",
    "        createAvgBarChart(predictionStats, f\"{title} + {i}\")\n",
    "        y_pred = plotModel(model, train_X, train_y, test_X, test_y,  f\"{title} + {i}\")\n",
    "        df = listAvg(df, i, modelVars, test_y, y_pred)\n",
    "    #df.to_csv(f\"Model Results-{title}.csv\", index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModelCVAvg(fileNameTrain, fileNameTest, desc, model, title, trainName, distributor = None):\n",
    "    train_X, train_y, test_X, test_y = makeTrainAndTest(fileNameTrain, fileNameTest, 'pIC50', desc)\n",
    "    avgResults = pd.DataFrame(data= [], columns=['Fold', 'Number of Molecules', 'r2', 'rmsd', 'bias', 'sdep', 'Model', 'Descriptor', 'Index', 'Train Set'])\n",
    "    for i in range(1, 4):\n",
    "        _,_, avgVals = loopedKfoldCrossVal(model, 10, train_X, train_y, f\"{title}-{model}-{descr}-{i}\")\n",
    "        avgVals['Model'] = model\n",
    "        avgVals['Descriptor'] = descr\n",
    "        avgVals['Index'] = i\n",
    "        avgVals['Train Set'] = trainName\n",
    "        avgResults = pd.concat([avgResults, avgVals])\n",
    "    return avgResults"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
